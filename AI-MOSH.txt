AI-MOSH
- What Large Language Models (LLM) are
- What we can do with them
- How to use them effectively
- Practical concepts: tokens, cost, model selection, etc


- AI engineer is not the same as a machine learning engineer.
- Machine learning engineers build and train model, they clean data, tune architectures, and optimize training pipelines.
    It's math - heavy and research - focused.
- AI engineers, on the other hand, use pre-trained models, especially LLM, to build smarter applications.
The don't need to understand the maths behind the model, the need to understand how to use it and how to integrate it into real world apps.

SUMMARIZATION, TRANSLATION, INTELLIGENCE SEARCH, AUTOMATION, AND PERSONALIZED UX.


ESSENTIAL AI SKILLS
- Large Language Models (LLMs)
- Prompt Engineering
- Retrieveal- Augmented Generation (RAG)
- Vector Databases
- Building Agents


What is a LLM
A system that's trained to understand and gnerate human Language
Training matters a lot

As a developers we have to know how to implement language models into aplications.

A typical structure 

-   Front-end
-   Back-end
-   Database
-   LLM. 


1 SUMMARIZATION. Amazon summaries revies
2- Content genaration. Emails, social media posts
3- Text Classification. 
    - Spam or not?
    - Review: positive or negative?
    - Ticket: billing, login, etc?
4- TRANSLATION
5- Data extracting: We can give an LLM some messy text, like a PDF, and ask it to 
    pull out structured data like invoice number, amount, names, addresss, and so on.
6- CHAT INTERFACE

Input => LLM => Response

TOKENS
https://platform.openai.com/tokenizer?ref=haihai.ai
Tokens directly impact cost

Generate 1M output tokens GPT-4o mini => 0.6&
Generate 1M output tokens GPT-4.1 => 8$

SIZE matters

Tokens cost money AND
there is a limit to how many tokens a model can handle at once CONTEXT WINDOW

CONTEXT WINDOW includes
Our prompt (input)
Model's Response
The chat history





